{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df16d6de-9250-4ade-8148-64fd895e03a0",
   "metadata": {},
   "source": [
    "DETECÇÃO DE \"FAKE NEWS\" UTILIZANDO INTELIGENCIA ARTIFICIAL.<br>\n",
    "César Augusto C. Filho1, Francisco Cláudio de Q. Nascimento2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a5e4a-66a2-4300-a181-510f1d3ace68",
   "metadata": {},
   "source": [
    "Criando Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade5b7b-d3a6-4e6b-a7d2-7d559bd908ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Definindo categorias de notícias verdadeiras e falsas\n",
    "true_news = [\n",
    "    \"Government announces new policies to boost economy.\",\n",
    "    \"Scientists discover new species in the Amazon rainforest.\",\n",
    "    \"Education reforms to improve school standards announced.\",\n",
    "    \"Healthcare workers to receive bonuses for their hard work.\",\n",
    "    \"Local community organizes charity event for the homeless.\"\n",
    "]\n",
    "\n",
    "fake_news = [\n",
    "    \"Celebrity caught in shocking scandal, shocking the world.\",\n",
    "    \"Aliens have been found living among us, says expert.\",\n",
    "    \"New miracle cure promises to cure all diseases instantly.\",\n",
    "    \"Politician accused of being a secret agent for another country.\",\n",
    "    \"Famous athlete retires to become a professional gamer.\"\n",
    "]\n",
    "\n",
    "# Expandir as amostras\n",
    "np.random.seed(42)\n",
    "true_news_expanded = np.random.choice(true_news, 500, replace=True)\n",
    "fake_news_expanded = np.random.choice(fake_news, 500, replace=True)\n",
    "\n",
    "# Criando os rótulos\n",
    "true_labels = np.ones(500)  # 1 para notícias verdadeiras\n",
    "fake_labels = np.zeros(500) # 0 para notícias falsas\n",
    "\n",
    "# Combinando os dados\n",
    "news_data = np.concatenate((true_news_expanded, fake_news_expanded))\n",
    "labels = np.concatenate((true_labels, fake_labels))\n",
    "\n",
    "# Criando o DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': news_data,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "# Exibindo as primeiras linhas do dataset\n",
    "print(df.head())\n",
    "\n",
    "# Salvando o dataset em um arquivo CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67a1cb-1793-413b-b460-f5aca8ff1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fake_news_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72feef5c-f799-4379-940b-da85fb1b06eb",
   "metadata": {},
   "source": [
    "Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45deb013-be27-4ca8-b15d-ccec1e057e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Carregando o dataset do arquivo CSV\n",
    "df = pd.read_csv('fake_news_dataset.csv')\n",
    "\n",
    "# Dividindo os dados em recursos (X) e rótulos (y)\n",
    "X = df['text']\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e818e-3978-4a8b-ae4a-f1089c3863c2",
   "metadata": {},
   "source": [
    "Extração de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a465be9-5f6a-4fde-83ab-db532eafcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_bow = bow_vectorizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# N-grams (bigramas, por exemplo)\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_ngram = ngram_vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d70fa1-6acd-4265-a023-b19af62c66c8",
   "metadata": {},
   "source": [
    "Divisão dos Dados em Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e934890-86cd-4db6-8b4d-0f61319c3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em treinamento e teste (usando Bag-of-Words como exemplo)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe159b-4581-4ab3-bae7-ff67e8b2ccc6",
   "metadata": {},
   "source": [
    "Construção e Treinamento dos Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e22d9c-2a45-4be7-a595-0f75f951284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização dos classificadores\n",
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Treinamento dos classificadores\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "lr_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217134e-d74f-4162-97cd-88a534bacf0a",
   "metadata": {},
   "source": [
    "Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c1049a-996f-4784-bc96-b454088591ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões\n",
    "nb_pred = nb_classifier.predict(X_test)\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "lr_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "# Cálculo do F1-score\n",
    "nb_f1 = f1_score(y_test, nb_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "\n",
    "# Exibição do F1-score\n",
    "print(f'Naive Bayes F1 Score: {nb_f1}')\n",
    "print(f'Random Forest F1 Score: {rf_f1}')\n",
    "print(f'Logistic Regression F1 Score: {lr_f1}')\n",
    "\n",
    "# Matrizes de Confusão\n",
    "print('Naive Bayes Confusion Matrix:', confusion_matrix(y_test, nb_pred))\n",
    "print('Random Forest Confusion Matrix:', confusion_matrix(y_test, rf_pred))\n",
    "print('Logistic Regression Confusion Matrix:', confusion_matrix(y_test, lr_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2b60b-bf9c-458d-9d13-fb268da0b7fb",
   "metadata": {},
   "source": [
    "Ajuste de Parâmetros com GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a78340-8c3b-433d-8987-3f5ab8652da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parâmetros para ajuste de Naive Bayes (exemplo)\n",
    "nb_params = {'alpha': [0.5, 1.0, 2.0]}\n",
    "grid_nb = GridSearchCV(nb_classifier, nb_params, cv=5, scoring='f1')\n",
    "grid_nb.fit(X_train, y_train)\n",
    "\n",
    "# Parâmetros para ajuste de Logistic Regression (exemplo)\n",
    "lr_params = {'C': [0.1, 1, 10]}\n",
    "grid_lr = GridSearchCV(lr_classifier, lr_params, cv=5, scoring='f1')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# Seleção dos melhores parâmetros\n",
    "best_nb = grid_nb.best_estimator_\n",
    "best_lr = grid_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731ae5c-440a-4f9b-a762-8ae844dfafc0",
   "metadata": {},
   "source": [
    "Classificação com o Melhor Modelo e Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b6f9f-8f12-4a5e-83bf-3da6a4d1466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que Logistic Regression foi o melhor modelo\n",
    "final_model = best_lr\n",
    "\n",
    "# Salvando o modelo final\n",
    "joblib.dump(final_model, 'fake_news_model.pkl')\n",
    "\n",
    "# Carregando o modelo salvo para uso futuro\n",
    "# loaded_model = joblib.load('fake_news_model.pkl')\n",
    "\n",
    "# Previsão com probabilidade\n",
    "pred_prob = final_model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce39956-824f-48c2-a9c7-cac9eb0635c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4d0874-35a3-4d38-a6fa-fa844cdb156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.875804795174513\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[6199  882]\n",
      " [ 895 6332]]\n",
      "\n",
      "Random Forest F1 Score: 0.9441406830433378\n",
      "Random Forest Confusion Matrix:\n",
      " [[6590  491]\n",
      " [ 308 6919]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.9523274549027712\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[6683  398]\n",
      " [ 284 6943]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Melhor F1 Score: 0.9558461734087811\n",
      "Previsão: Fake\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Passo 1: Carregar e Pré-processar a Base de Dados\n",
    "df = pd.read_csv('WELFake_Dataset.csv')  # Substitua pelo caminho correto\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Definir as características e rótulos\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Passo 2: Extração de Features\n",
    "# Bag-of-Words\n",
    "bow_vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 1))\n",
    "X_bow = bow_vectorizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# N-grams (usando TF-IDF)\n",
    "X_ngrams = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Divisão dos Dados em Treino e Teste\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_ngrams, X_test_ngrams, _, _ = train_test_split(X_ngrams, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Passo 3: Treinamento dos Modelos de Classificação\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Avaliar os Modelos\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_bow, y_train)\n",
    "    y_pred = model.predict(X_test_bow)\n",
    "    print(f\"{model_name} F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Passo 4: Ajuste de Parâmetros com GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "print(f\"Melhor F1 Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Passo 5: Salvar o Melhor Modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Passo 6: Carregar e Usar o Modelo\n",
    "model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Exemplo de Classificação de Notícia\n",
    "user_input = \"Texto da notícia a ser classificada\"\n",
    "user_input_vectorized = tfidf_vectorizer.transform([user_input])\n",
    "prediction = model.predict(user_input_vectorized)\n",
    "print(f\"Previsão: {'Fake' if prediction[0] == 1 else 'Real'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b285b17-8d15-44ba-8253-207288ff87e2",
   "metadata": {},
   "source": [
    "CORRIGIDO E VÁLIDO - FUNCIONANDO 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a637193f-2d47-486f-b33c-d23578ada8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (Bag-of-Words) F1 Score: 0.875804795174513\n",
      "Naive Bayes (Bag-of-Words) Confusion Matrix:\n",
      " [[6199  882]\n",
      " [ 895 6332]]\n",
      "\n",
      "Random Forest (Bag-of-Words) F1 Score: 0.9441406830433378\n",
      "Random Forest (Bag-of-Words) Confusion Matrix:\n",
      " [[6590  491]\n",
      " [ 308 6919]]\n",
      "\n",
      "Logistic Regression (TF-IDF) F1 Score: 0.9492516203440949\n",
      "Logistic Regression (TF-IDF) Confusion Matrix:\n",
      " [[6660  421]\n",
      " [ 305 6922]]\n",
      "\n",
      "Melhores Parâmetros: {'C': 10, 'solver': 'liblinear'}\n",
      "Melhor F1 Score: 0.9601166680395744\n",
      "Previsão: Fake\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Passo 1: Carregar e Pré-processar a Base de Dados\n",
    "df = pd.read_csv('WELFake_Dataset.csv')  # Substitua pelo caminho correto\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Definir as características e rótulos\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Passo 2: Extração de Features\n",
    "# Bag-of-Words\n",
    "bow_vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 1))\n",
    "X_bow = bow_vectorizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Divisão dos Dados em Treino e Teste para Bag-of-Words\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Divisão dos Dados em Treino e Teste para TF-IDF\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Passo 3: Treinamento dos Modelos de Classificação\n",
    "models = {\n",
    "    'Naive Bayes (Bag-of-Words)': MultinomialNB(),\n",
    "    'Random Forest (Bag-of-Words)': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression (TF-IDF)': LogisticRegression(max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Avaliar os Modelos\n",
    "for model_name, model in models.items():\n",
    "    if 'Logistic Regression' in model_name:\n",
    "        # Treinamento e avaliação para TF-IDF\n",
    "        model.fit(X_train_tfidf, y_train_tfidf)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        print(f\"{model_name} F1 Score: {f1_score(y_test_tfidf, y_pred, average='weighted')}\")\n",
    "        print(f\"{model_name} Confusion Matrix:\\n {confusion_matrix(y_test_tfidf, y_pred)}\\n\")\n",
    "    else:\n",
    "        # Treinamento e avaliação para Bag-of-Words\n",
    "        model.fit(X_train_bow, y_train_bow)\n",
    "        y_pred = model.predict(X_test_bow)\n",
    "        print(f\"{model_name} F1 Score: {f1_score(y_test_bow, y_pred, average='weighted')}\")\n",
    "        print(f\"{model_name} Confusion Matrix:\\n {confusion_matrix(y_test_bow, y_pred)}\\n\")\n",
    "\n",
    "# Passo 4: Ajuste de Parâmetros com GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "print(f\"Melhor F1 Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Passo 5: Salvar o Melhor Modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Passo 6: Carregar e Usar o Modelo\n",
    "model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Exemplo de Classificação de Notícia\n",
    "user_input = \"Texto da notícia a ser classificada\"\n",
    "user_input_vectorized = tfidf_vectorizer.transform([user_input])\n",
    "prediction = model.predict(user_input_vectorized)\n",
    "print(f\"Previsão: {'Fake' if prediction[0] == 1 else 'Real'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303c1cf-93ed-427d-a907-c21bb3795b9e",
   "metadata": {},
   "source": [
    "com inclusão do Recall, precisão e acuracia. além do f1 score e matriz de confusçao. Porem apresenta um erro devido o algoritmo de Logistic Regression não conseguiu convergir, correção possível: LogisticRegression(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40113be9-a6a1-4a2e-9d09-f16199f52931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Metrics:\n",
      "Accuracy: 0.8758\n",
      "Precision: 0.8758\n",
      "Recall: 0.8758\n",
      "F1 Score: 0.8758\n",
      "Confusion Matrix:\n",
      "[[6199  882]\n",
      " [ 895 6332]]\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.9442\n",
      "Precision: 0.9444\n",
      "Recall: 0.9442\n",
      "F1 Score: 0.9441\n",
      "Confusion Matrix:\n",
      "[[6590  491]\n",
      " [ 308 6919]]\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9493\n",
      "Precision: 0.9494\n",
      "Recall: 0.9493\n",
      "F1 Score: 0.9493\n",
      "Confusion Matrix:\n",
      "[[6660  421]\n",
      " [ 305 6922]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Melhor F1 Score: 0.9558461734087811\n",
      "Previsão: Fake\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Passo 1: Carregar e Pré-processar a Base de Dados\n",
    "df = pd.read_csv('WELFake_Dataset.csv')  # Substitua pelo caminho correto\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Definir as características e rótulos\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Passo 2: Extração de Features\n",
    "# Bag-of-Words\n",
    "bow_vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 1))\n",
    "X_bow = bow_vectorizer.fit_transform(X)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# N-grams (usando TF-IDF)\n",
    "X_ngrams = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Divisão dos Dados em Treino e Teste\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train_ngrams, X_test_ngrams, _, _ = train_test_split(X_ngrams, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Passo 3: Treinamento dos Modelos de Classificação\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Avaliar os Modelos\n",
    "for model_name, model in models.items():\n",
    "    if model_name != 'Logistic Regression':\n",
    "        model.fit(X_train_bow, y_train)\n",
    "        y_pred = model.predict(X_test_bow)\n",
    "    else:\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "    # Calcular e exibir as métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "# Passo 4: Ajuste de Parâmetros com GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
    "print(f\"Melhor F1 Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Passo 5: Salvar o Melhor Modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "# Passo 6: Carregar e Usar o Modelo\n",
    "model = joblib.load('best_model.pkl')\n",
    "\n",
    "# Exemplo de Classificação de Notícia\n",
    "user_input = \"Texto da notícia a ser classificada\"\n",
    "user_input_vectorized = tfidf_vectorizer.transform([user_input])\n",
    "prediction = model.predict(user_input_vectorized)\n",
    "print(f\"Previsão: {'Fake' if prediction[0] == 1 else 'Real'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552eec6-0796-420d-9c6a-d2deb85f306a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
